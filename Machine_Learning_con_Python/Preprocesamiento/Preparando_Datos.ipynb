{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchos algoritmos hacen asunciones sobre los datos. A menudo es una buena idea preparar nuestros datos de forma que estén expuestos de la mejor forma posible a las necesidades de cada algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reescalando Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando los datos están compuestos de una gran variedad de atributos con diferentes escalas, muchos algoritmos se pueden beneficiar de reescalar estos atributos y poner todos ellos en la misma escala. Este se conoce como normalización de atributos ya que estos son reescalados en el rango 0,1. Esto es realmente útil para optimizar algoritmos que hacen uso de gradientes como la regresión, o algoritmos que hacen uso de pesos como las redes neuronales, o algoritmos que se basan en distancias como el algoritmo de K vecinos más cercano. Podemos reescalar nuestros datos a partir de la clase **MinMaxScaler** de sckit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    preg    plas    pres    skin    test    mass    pedi    age    class \n",
       "0       6     148      72      35       0    33.6   0.627     50        1\n",
       "1       1      85      66      29       0    26.6   0.351     31        0\n",
       "2       8     183      64       0       0    23.3   0.672     32        1\n",
       "3       1      89      66      23      94    28.1   0.167     21        0\n",
       "4       0     137      40      35     168    43.1   2.288     33        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "col_names = [ ' preg ' , ' plas ' , ' pres ' , ' skin ' , ' test ' , ' mass ' , ' pedi ' , ' age ' , ' class ' ]\n",
    "df = pd.read_csv('pima-indians-diabetes.data.csv', names = col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.353 0.744 0.59  0.354 0.    0.501 0.234 0.483]\n",
      " [0.059 0.427 0.541 0.293 0.    0.396 0.117 0.167]\n",
      " [0.471 0.92  0.525 0.    0.    0.347 0.254 0.183]\n",
      " [0.059 0.447 0.541 0.232 0.111 0.419 0.038 0.   ]\n",
      " [0.    0.688 0.328 0.354 0.199 0.642 0.944 0.2  ]]\n"
     ]
    }
   ],
   "source": [
    "#Obtenemos el numpy array\n",
    "df_array = df.values\n",
    "\n",
    "#Separamos entre los predictores y la clase\n",
    "X = df_array[:, 0:8]\n",
    "Y = df_array[:,8]\n",
    "\n",
    "#Configuramos el scaler\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "#Hacemos el fit y el transform\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "#Configuramos para mostrar los datos con tres decimales\n",
    "np.set_printoptions(precision = 3)\n",
    "\n",
    "#Vemos el resultado\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estandarizando datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estandarización es una técnica útil para transformar atributos con una distribución gaussiana con media y desviación diferentes a cero y la unidad a una distribución gaussiana estándar con  media 0 y desviación estándar 1. Es una técnica adecuada para algoritmos que asumen una distribución gaussiana en las variables de entrada y trabajan mejor con datos reescalados, como por ejemplo, regresión lineal, regresión logística o análisis de discriminación lineal. Podemos estandarizar nuestros datos haciendo uso de la clase **StandardScaler** de sckit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64   0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n",
      " [-0.845 -1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n",
      " [ 1.234  1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n",
      " [-0.845 -0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n",
      " [-1.142  0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n"
     ]
    }
   ],
   "source": [
    "#Hacemos el fit y el transform\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "\n",
    "#FIjamos la precisión\n",
    "np.set_printoptions(precision = 3)\n",
    "print(rescaledX[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Normalizando datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La normalización en scikit-learn es referida a reescalar cada observación. Cada muestra (cada fila de nuestra matriz de datos) con al menos un componente diferente de cero se reescala independientemente de otras muestras, de modo que se norma sea igual a la unidad. Este método de pre-procesamiento puede ser muy útil para datos esparcidos (con muchos ceros) con atributos de diferentes escalas cuando usamos algoritmos donde sus valores de entrada son pesos como ocurre en redes neuronales y algoritmos que se basan en distancias como es el caso de K-vecinos más cercanos (KNN). Podemos normalizar nuestros datos haciendo uso de la clase **Normalizer** de la librería scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.034 0.828 0.403 0.196 0.    0.188 0.004 0.28 ]\n",
      " [0.008 0.716 0.556 0.244 0.    0.224 0.003 0.261]\n",
      " [0.04  0.924 0.323 0.    0.    0.118 0.003 0.162]\n",
      " [0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139]\n",
      " [0.    0.596 0.174 0.152 0.731 0.188 0.01  0.144]]\n"
     ]
    }
   ],
   "source": [
    "#Hacemos el fit y el transform\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "\n",
    "#Fijamos la precisión\n",
    "np.set_printoptions(precision = 3)\n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarizando datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos binarizar nuestros datos haciendo uso de un umbral. Todos los valores por debajo de ese umbral se marcarán como uno y los que sean menores o iguales se marcarán como cero. Esto puede ser útilcuando tenemos probabilidades y queremos conseguir valores nítidos. También, puede ser útil para añadir nuevas características que indiquen algo significativo. Podemos binarizar nuestro conjunto de datos haciendo uso de la clase **Binarizer** de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#Hacemos el fit y el transform\n",
    "scaler = Binarizer(threshold= 0.0).fit(X)\n",
    "binarizerX = scaler.transform(X)\n",
    "\n",
    "#Fijamos la precisión\n",
    "np.set_printoptions(precision = 3)\n",
    "print(binarizerX[0:5,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
