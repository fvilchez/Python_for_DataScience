{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas usadas a la hora de evaluar un algoritmo son muy importantes. La elección de las métricas influye en el rendimiento de nuestro algoritmo, en la ponderación de las diferentes característcias y en la elección final de que algoritmo usaremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas para problemas de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los problemas de clasificación son quizás el tipo de problema más común en el aprendizaje automático. Tenemos una gran cantidad de métricas que pueden usarse para evaluar las predicciones de estos problemas:\n",
    "\n",
    "* **Classification accuracy**\n",
    "\n",
    "* **Logarithmic Loss**\n",
    "\n",
    "* **Area Under ROC Curve**\n",
    "\n",
    "* ** Confusion Matrix**\n",
    "\n",
    "* **Classification Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión (accuracy) se define como el número de predicciones realizadas de forma adecuada entre el número total de predicciones realizadas. Esta es la métrica evaluación más usada, sin embargo, se trata de una de las métricas que más erroneamente es usada. Realmente solo es adecuada cuadno el número de observaciones de cada clase es la misma y todas las predicciones y todos los errores de predicción son igual de importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.770 (0.048)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class']\n",
    "df = pd.read_csv(filename, names=names)\n",
    "\n",
    "#Separamos entre los predictores y la variable a predecir\n",
    "X = df.values[:, 0:8]\n",
    "Y = df.values[:,8]\n",
    "\n",
    "#Preparamos el modelo\n",
    "kFold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = cross_val_score(model, X, Y, cv = kFold, scoring = scoring)\n",
    "print('Accuracy: %.3f (%.3f)' % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logarithmic Loss (logloss) es una métrica de rendimiento que lo que hace es penalizar aquellas clasificaciones realizadas de forma incorrecta. Para calcular esta métrica, el clasificador debe asignar una probabilidad a cada clase en lugar de proporcionar la clase más probable. Un clasificador perfecto debería de tener un logloss nulo.\n",
    "\n",
    "La métrica logloss penaliza en gran medida a los clasificadores que confían en una clasificación incorrecta. Por ejemplo, si para un observación particular, el clasificador asigna una probabilidad muy pequeña a la clase correcta, entonces esta métrica penaliza de forma considerable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: -0.493 (0.047)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class']\n",
    "df = pd.read_csv(filename, names=names)\n",
    "\n",
    "#Separamos entre los predictores y la variable a predecir\n",
    "X = df.values[:, 0:8]\n",
    "Y = df.values[:,8]\n",
    "\n",
    "#Preparamos el modelo\n",
    "kFold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'neg_log_loss'\n",
    "results = cross_val_score(model, X, Y, cv = kFold, scoring = scoring)\n",
    "print('Accuracy: %.3f (%.3f)' % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area bajo la curva ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El área bajo la curva ROC (AUC) es una métrica de rendimiento para problemas de tipo binario. El AUC representa la abilidad de un modelo de discriminar entre clases positivas y negativas. Un área de 1.0 representa un modelo que hace todas las predicciones perfectas. Un área de 0.5 representa un modelo completamente aleatorio. La curva ROC puede ser descompuesta en sensibilidad (sensitivity) y especificidad (specifity).\n",
    "\n",
    "* **Sensitivity:** es el ratio de verdaderos positivos (tru positive) también llamado recall. Es el número de instancias de la clase positiva que se predijeron de forma correcta.\n",
    "\n",
    "* **Specifity:** también llamado como ratio de verdaderos negativos. Es el número de instancias de la clase negativa que se predijeron de forma adecuada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.824 (0.041)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class']\n",
    "df = pd.read_csv(filename, names=names)\n",
    "\n",
    "#Separamos entre los predictores y la variable a predecir\n",
    "X = df.values[:, 0:8]\n",
    "Y = df.values[:,8]\n",
    "\n",
    "#Preparamos el modelo\n",
    "kFold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(model, X, Y, cv = kFold, scoring = scoring)\n",
    "print('Accuracy: %.3f (%.3f)' % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión es una representación práctica de la precisión de un modelo con dos o más clases. La tabla representa predicciones en el eje X y resultados de precisión en el eje Y. Las celdas de la tabla son el número de predicciones realizadas por nuestro algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130  17]\n",
      " [ 38  46]]\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class']\n",
    "df = pd.read_csv(filename, names=names)\n",
    "\n",
    "#Separamos entre los predictores y la variable a predecir\n",
    "X = df.values[:, 0:8]\n",
    "Y = df.values[:,8]\n",
    "test_size = 0.3\n",
    "\n",
    "#Preparamos el modelo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = test_size, random_state = 7)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos indica que de aquellas predicciones que eran 0, realmente se han clasificado como cero un total de 130 observaciones, mientras que un total de 17 que eran 0 se han clasificado como 1. También nos indica que un total de 46 observaciones que eran 1 se clasificaron como 1, mientras que un total de 38 que eran 1 fueron clasificadas como 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.88      0.83       147\n",
      "        1.0       0.73      0.55      0.63        84\n",
      "\n",
      "avg / total       0.76      0.76      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class']\n",
    "df = pd.read_csv(filename, names=names)\n",
    "\n",
    "#Separamos entre los predictores y la variable a predecir\n",
    "X = df.values[:, 0:8]\n",
    "Y = df.values[:,8]\n",
    "test_size = 0.3\n",
    "\n",
    "#Preparamos el modelo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = test_size, random_state = 7)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = classification_report(y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas para problemas de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación veremos tres de las métricas más usadas en los problemas de regresión:\n",
    "\n",
    "* **Mean Absolute Error (MAE)**\n",
    "\n",
    "* **Mean Squared Error (MSE)**\n",
    "\n",
    "* **R2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error media absoluto es la suma de las diferencias absolutas entre las predicciones y el valor real. Esta métrica nos da una idea de la magnitud del error, pero no nos da una idea de la dirección del error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.20396.90</td>\n",
       "      <td>14.33</td>\n",
       "      <td>16.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "500  0.22438  0.0   9.69     0  0.585  6.027  79.7  2.4982    6  391.0   \n",
       "\n",
       "         PTRATIO      B  LSTAT  MEDV  \n",
       "500  19.20396.90  14.33   16.8   NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe.PTRATIO == '19.20396.90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -4.017 (2.089)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO', 'B', \n",
    "         'LSTAT', 'MEDV']\n",
    "dataframe = pd.read_csv('boston.csv', delim_whitespace=True, names=names)\n",
    "\n",
    "#Separamos entre variables predictoras y variable a predecir\n",
    "X = dataframe.values[:, 0:13]\n",
    "Y = dataframe.values[:, 13]\n",
    "\n",
    "#Fijamos el modelo\n",
    "kFold = KFold(n_splits=10, random_state = 7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = cross_val_score(model, X, Y, cv = kFold, scoring = scoring)\n",
    "print(\"MAE: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "El error cuadrático medio tiene un significado parecido al MAE, en el sentido que nos indica la dimensión del error. Se calcula como la suma de las diferencias al cuadrado entre los valores predichos y el real, de esta forma esta métrico penaliza en mayor medida los errores grandes. Si tomamos la raíz cuadrada de esta métrica obtenemos la métrica conocida como RMSE, que se encuentran en las unidades originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -34.846 (45.551)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO', 'B', \n",
    "         'LSTAT', 'MEDV']\n",
    "dataframe = pd.read_csv('boston.csv', delim_whitespace=True, names=names)\n",
    "\n",
    "#Separamos entre variables predictoras y variable a predecir\n",
    "X = dataframe.values[:, 0:13]\n",
    "Y = dataframe.values[:, 13]\n",
    "\n",
    "#Fijamos el modelo\n",
    "kFold = KFold(n_splits=10, random_state = 7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv = kFold, scoring = scoring)\n",
    "print(\"MSE: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métrica R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La métrica R2 nos indica lo bien que se están ajustando las predicciones a los valores reales. EN estadística esta métrica es conocida como coeficiente de determinación. Es un valor que va entre 0 y 1, donde 0 indica ajuste nulo y 1 indica ajuste perfecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.193 (0.614)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO', 'B', \n",
    "         'LSTAT', 'MEDV']\n",
    "dataframe = pd.read_csv('boston.csv', delim_whitespace=True, names=names)\n",
    "\n",
    "#Separamos entre variables predictoras y variable a predecir\n",
    "X = dataframe.values[:, 0:13]\n",
    "Y = dataframe.values[:, 13]\n",
    "\n",
    "#Fijamos el modelo\n",
    "kFold = KFold(n_splits=10, random_state = 7)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv = kFold, scoring = scoring)\n",
    "print(\"R2: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
