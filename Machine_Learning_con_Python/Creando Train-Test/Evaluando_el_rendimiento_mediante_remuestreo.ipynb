{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, LeaveOneOut, ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder evaluar el rendimiento de un algoritmo necesitamos conocer como se comporta dicho alogoritmo ante datos no vistos. La mejor forma de evaluar el rendimiento de un algoritmo sería haciendo predicciones para datos nuevos para los cuales conocemos cuá debería ser el resultado. La segunda mejor forma es hacer uso de técnicas estadísticas llamadas métodos de remuestreo, que permiten hacer estimaciones precisas de como de bien se comportará nuestro algoritmo antes nuevos datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluando algoritmos de aprendizaje automático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos evaluar nuestro algoritmo con datos que no fueron usados en el entrenamiento de nuestro algoritmo. La evaluaciń es una estimación de como de bien se podría comportar nuestro algoritmo en la práctica. No es una garantía de rendimiento. Una vez hemos estimado el rendimiento de nuestro algoritmo, podemos reentrenar nuestro algoritmo final con todo el conjunto de datos. Entre las cuatro técnicas más usadas a la hora de entrenar un algoritmo a partir de un conjunto de datos tenemos:\n",
    "\n",
    "* **Train and Test Sets**\n",
    "\n",
    "* **k-fold Cross-Validation**\n",
    "\n",
    "* **Leave One Out Cross-Validation**\n",
    "\n",
    "* **Repeated Random Test-Train Splits**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma más simple que tenemos a la hora de evaluar el rendimiento de un algoritmo de aprendizaje automático es haciendo uso de dos conjuntos de datos: uno para entrenar y otro para evaluar. Podemos coger nuestro conjunto de datos original y dividirlo en dos partes. Una primera parte para entrenar nuestro algoritmo y una segunda parte para testear nuestro algoritmo. El tamaño de cada una de las partes depende de las dimensiones de nuestro conjunto de datos original, una división muy común es tomar el 67% para entrenamiento y 33% para testear.\n",
    "\n",
    "Esta técnica tiene la ventaja de que es muy rápida. Es ideal para conjuntos de datos muy grandes, donde tenemos evidencia de que ambas divisiones son representativas del problema subyacente.\n",
    "\n",
    "La principal desventaja de esta técnica es que puede tener una elevada varianza. Esto significa que diferentes divisiones pueden dar lugar a que nuestro algoritmo tenga diferente precisón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 76.190%\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el conjunto de datos\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' ,  'class']\n",
    "dataframe = pd.read_csv(filename, names=names)\n",
    "\n",
    "#Separamos en variables predictoras y variable a predecir\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "#Fijamos el tamaño del conjunto de test y aplicamos train_test_split\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = test_size, random_state = 7)\n",
    "\n",
    "#FIjamos el modelo\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "result = model.score(X_test, y_test)\n",
    "\n",
    "print('Precision: %.3f%%' % (result*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation es un enfoque para estimar el rendimiento de una algoritmo de aprendizaje automático con una varianza menor que la técnica train-test split. Esta técnica lo que hace es dividir nuestro conjunto de datos en k partes (k=5, k=10, ...). Cada una de las divisiones de datos es llamada fold. Tras dividir el dataset, lo que se hace es que cada una de las partes es usada como test y el resto como train. Por ejemplo para un caso que tenemos un dataset **df**, y un cross-validation con k=3. En este caso df es dividido en tres partes (df1, df2, df3) de forma que tendríamos tres iteraciones:\n",
    "\n",
    "* En la primera iteración df1 y df2 son usadas para entrenar nuestro algoritmo y df3 para evaluarlo\n",
    "\n",
    "* En la segunda iteración df2 y df3 son usadas para entrenar nuestro algoritmo y df1 para evaluarlo\n",
    "\n",
    "* En la primera iteración df1 y df3 son usadas para entrenar nuestro algoritmo y df2 para evaluarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras aplicar cross-validation tendremos k resultados de precisión, estos resultados pueden resumirse a partir de la media y de la desviación estándar. Esta forma es más fiable, ya que el algoritmo es entrenado22 y evaluado múltiples veces con diferentes datos. El valor de k-elegido debe ser un valor acorde con la dimensión de nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.951% (4.841%)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el conjunto de datos\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' ,  'class']\n",
    "dataframe = pd.read_csv(filename, names=names)\n",
    "\n",
    "#Separamos en variables predictoras y variable a predecir\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "#Hacemos uso del k-fold cross validation\n",
    "kfold = KFold(n_splits = 10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv = kfold)\n",
    "\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave One Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos configurar la técnica cross-validation para que el tamaño del fold sea 1 (es decir nuestro valor de k será igual al número de observaciones de nuestro conjunto de datos). Esta variación de cross-validation es llamada leave-one-out cross-validation. El resultado es un gran número de medidas que puede ser resumidas para ofrecer una estimación más razonable de la precisión de nuestro modelo. Su gran desventaja es que computacionalmente es muy costoso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.823% (42.196%)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el conjunto de datos\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' ,  'class']\n",
    "dataframe = pd.read_csv(filename, names=names)\n",
    "\n",
    "#Separamos en variables predictoras y variable a predecir\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "#Hacemos uso de la técnica LeaveOneOut\n",
    "loocv = LeaveOneOut()\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv = loocv)\n",
    "print('Accuracy: %.3f%% (%.3f%%)' % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra variación de la técnica k-fold cross-validation es crear un split aleatorio de datos, de igual que el train-test split, pero repitiendo el proceso k veces. Es decir, la idea es hacer un train-test 67-33 pero k veces, de forma que tengamos k evaluaciones distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.496% (1.698%)\n"
     ]
    }
   ],
   "source": [
    "#Cargamos el conjunto de datos\n",
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' ,  'class']\n",
    "dataframe = pd.read_csv(filename, names=names)\n",
    "\n",
    "#Separamos en variables predictoras y variable a predecir\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "#Hacemos uso de ShuffleSplit\n",
    "n_splits = 10\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "kfold = ShuffleSplit(n_splits = n_splits, test_size=test_size, random_state=seed)\n",
    "\n",
    "#Fijamos el modelo\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv = kfold)\n",
    "print('Accuracy: %.3f%% (%.3f%%)' % (results.mean()*100, results.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
