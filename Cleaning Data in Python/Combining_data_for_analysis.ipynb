{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En determinadas ocasiones es posible que tengamos que concatenar determinados conjuntos de datos. La librería Pandas nos proporciona el método **concat** que nos permite concatenar varios conjuntos de datos por filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date/Time         Lat         Lon    Base\n",
      "0  4/1/2014 0:11:00  40769.0000    -73.9549  B02512\n",
      "1  4/1/2014 0:17:00     40.7267    -74.0345  B02512\n",
      "2  4/1/2014 0:21:00     40.7316    -73.9873  B02512\n",
      "3  4/1/2014 0:28:00     40.7588    -73.9776  B02512\n",
      "4  4/1/2014 0:33:00     40.7594    -73.9722  B02512\n",
      "5  4/1/2014 0:33:00     40.7383    -74.0403  B02512\n",
      "6  4/1/2014 0:39:00     40.7223    -73.9887  B02512\n",
      "7  4/1/2014 0:45:00  40762.0000 -73979.0000  B02512\n",
      "8  4/1/2014 0:55:00     40.7524    -73.9960  B02512\n",
      "9  4/1/2014 1:01:00     40.7575    -73.9846  B02512\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Cargamos los datos\n",
    "uber1 = pd.read_csv('uber_1.csv')\n",
    "uber2 = pd.read_csv('uber_2.csv')\n",
    "uber3 = pd.read_csv('uber_3.csv')\n",
    "\n",
    "#Procedemos a concatenar los tres conjuntos de datos para obtener de esta forma un único dataframe\n",
    "row_concat = pd.concat([uber1, uber2, uber3])\n",
    "\n",
    "#Vemos el resultado de las 10 primeras observaciones\n",
    "print(row_concat.head(n = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método **concat()** dispone del parámetro **axis**, este valor por defecto toma el valor de 0 lo que indica que concatenará por filas, mientras que si toma el valor de 1 esta concatenación será por columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding files that match a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que queremos concatenar cientos o miles de dataframes, de forma que necesitamos realizar la lectura de cada uno de estos conjuntos de datos y luego concatenarlos. Realizar la lectura fichero por fichero, no parece ser una forma muy óptima. La función **glob** de Python, nos retorna una lista de todos los ficheros que coinciden con el patrón que le pasamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uber_3.csv', 'uber_2.csv', 'dob_job_application_filings_subset.csv', 'duplicate.csv', 'gapminder.csv', 'uber_1.csv', 'tips.csv', 'tb.csv', 'ebola.csv', 'nyc_uber_2014.csv', 'airquality.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "#Buscamos todos los ficheros csv\n",
    "files = glob.glob('*.csv')\n",
    "\n",
    "#Mostramos el resultado\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uber_3.csv', 'uber_2.csv', 'uber_1.csv']\n"
     ]
    }
   ],
   "source": [
    "#Buscamos los ficheros que tienen el valor _\n",
    "files = glob.glob('*_?.csv')\n",
    "\n",
    "#Mostramos el resultado\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos todos los archivos que queremos leer en una lista podemos crearnos una lista de dataframes y tras esto pasarselo a la función concat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date/Time         Lat         Lon    Base\n",
      "0  6/1/2014 0:01:00     40.7131    -74.0097  B02512\n",
      "1  6/1/2014 0:04:00     40.3461 -74661.0000  B02512\n",
      "2  6/1/2014 0:04:00     40.7555    -73.9833  B02512\n",
      "3  6/1/2014 0:07:00  40688.0000    -74.1831  B02512\n",
      "4  6/1/2014 0:08:00     40.7152    -73.9917  B02512\n",
      "5  6/1/2014 0:08:00     40.7282 -73991.0000  B02512\n",
      "6  6/1/2014 0:08:00     40.3042    -73.9794  B02512\n",
      "7  6/1/2014 0:09:00  40727.0000    -73.9915  B02512\n",
      "8  6/1/2014 0:10:00     40.7221    -73.9965  B02512\n",
      "9  6/1/2014 0:11:00     40.7153    -74.0146  B02512\n"
     ]
    }
   ],
   "source": [
    "#Obtenemos la lista de dataframes a concatenar\n",
    "list_df_uber = [pd.read_csv(file) for file in files]\n",
    "\n",
    "#Concatenamos los dataframes\n",
    "df_uber_concat = pd.concat(list_df_uber)\n",
    "\n",
    "#Mostramos el resultado\n",
    "print(df_uber_concat.head(n = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-to-1 data merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La unión(merge) de varios datasets, nos permite compactar información de forma que podamos realizar un análisis mas completo de los datos. A la hora de realizar un Merge entre varios dataframes podemos tener varios posibilidades:\n",
    "\n",
    "* one-to-one merge: este caso es en el cual al cruzar ambos conjuntos de datos no tenemos duplicados.\n",
    "\n",
    "* Many-to-one merge:\n",
    "\n",
    "* Many-to-Many merge:\n",
    "\n",
    "Para cruzar datos contamos con el método **merge()** de la librería Pandas. Este método recibe los dos conjuntos de datos que deseamos unir, y luego dispone del parámetro **on** en el cual indicamos por que columna deseamos realizar la unión. En caso de que las columnas por las que deseamos realizar la unión tenga un nombre distinto podemos hacer uso de los parámetros **left_on** y **right_on**, mediante los cuales indicamos las columnas por las que deseamos realizar la unión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "site = pd.read_csv('site.csv')\n",
    "print(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    734   DR-3  1939-01-07\n",
      "2    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "visited = pd.read_csv('visited.csv')\n",
    "print(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "#Hacemos un merge entre ambos datos por los campos name y site\n",
    "df_merge = pd.merge(left = site, right = visited, left_on = 'name', right_on = 'site')\n",
    "\n",
    "#Vemos el resultado \n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many-to-1 data merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este tipo de merge una de las tablas dispone de valores repetidos del campo por el cual vamos a cruzar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "site = pd.read_csv('site.csv')\n",
    "print(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "visited_2 = pd.read_csv('visited_2.csv')\n",
    "print(visited_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
      "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
      "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "#Hacemos el merge\n",
    "df_merge = pd.merge(left = site, right = visited_2, left_on = 'name', right_on = 'site')\n",
    "\n",
    "#Mostramos el resultado \n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many-to-many data merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El último caso es aquel en el que ambas tablas disponen de valores repetidos en la columna por la cula se va producir el merge. En estos caso los valores apareceran por duplicado, es decir, para cada clave duplicada apareceran combinaciones de pares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    taken  person  quant  reading\n",
      "0      619    dyer   rad     9.82\n",
      "1      619    dyer   sal     0.13\n",
      "2      622    dyer   rad     7.80\n",
      "3      622    dyer   sal     0.09\n",
      "4      734      pb   rad     8.41\n",
      "5      734    lake   sal     0.05\n",
      "6      734      pb  temp   -21.50\n",
      "7      735      pb   rad     7.22\n",
      "8      735     NaN   sal     0.06\n",
      "9      735     NaN  temp   -26.00\n",
      "10     751      pb   rad     4.35\n",
      "11     751      pb  temp   -18.50\n",
      "12     751    lake   sal     0.10\n",
      "13     752    lake   rad     2.19\n",
      "14     752    lake   sal     0.09\n",
      "15     752    lake  temp   -16.00\n",
      "16     752     roe   sal    41.60\n",
      "17     837    lake   rad     1.46\n",
      "18     837    lake   sal     0.21\n",
      "19     837     roe   sal    22.50\n",
      "20     844     roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "survey = pd.read_csv('survey.csv')\n",
    "print(survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
      "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
      "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "#Mostramos los datos con los que vamos a mergear\n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 10)\n"
     ]
    }
   ],
   "source": [
    "#Procedemos a mergear por el campo ident y taken\n",
    "df_merge = pd.merge(left = df_merge, right = survey, left_on = 'ident', right_on = 'taken ')\n",
    "\n",
    "#Vemos el tamaño de nuestro conjunto de datos mergeado\n",
    "print(df_merge.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name    lat    long  ident   site       dated  taken  person  quant  \\\n",
      "0    DR-1 -49.85 -128.57    619   DR-1  1927-02-08     619    dyer   rad   \n",
      "1    DR-1 -49.85 -128.57    619   DR-1  1927-02-08     619    dyer   sal   \n",
      "2    DR-1 -49.85 -128.57    622   DR-1  1927-02-10     622    dyer   rad   \n",
      "3    DR-1 -49.85 -128.57    622   DR-1  1927-02-10     622    dyer   sal   \n",
      "4    DR-1 -49.85 -128.57    844   DR-1  1932-03-22     844     roe   rad   \n",
      "5    DR-3 -47.15 -126.72    734   DR-3  1939-01-07     734      pb   rad   \n",
      "6    DR-3 -47.15 -126.72    734   DR-3  1939-01-07     734    lake   sal   \n",
      "7    DR-3 -47.15 -126.72    734   DR-3  1939-01-07     734      pb  temp   \n",
      "8    DR-3 -47.15 -126.72    735   DR-3  1930-01-12     735      pb   rad   \n",
      "9    DR-3 -47.15 -126.72    735   DR-3  1930-01-12     735     NaN   sal   \n",
      "10   DR-3 -47.15 -126.72    735   DR-3  1930-01-12     735     NaN  temp   \n",
      "11   DR-3 -47.15 -126.72    751   DR-3  1930-02-26     751      pb   rad   \n",
      "12   DR-3 -47.15 -126.72    751   DR-3  1930-02-26     751      pb  temp   \n",
      "13   DR-3 -47.15 -126.72    751   DR-3  1930-02-26     751    lake   sal   \n",
      "14   DR-3 -47.15 -126.72    752   DR-3         NaN     752    lake   rad   \n",
      "15   DR-3 -47.15 -126.72    752   DR-3         NaN     752    lake   sal   \n",
      "16   DR-3 -47.15 -126.72    752   DR-3         NaN     752    lake  temp   \n",
      "17   DR-3 -47.15 -126.72    752   DR-3         NaN     752     roe   sal   \n",
      "18  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14     837    lake   rad   \n",
      "19  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14     837    lake   sal   \n",
      "20  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14     837     roe   sal   \n",
      "\n",
      "    reading  \n",
      "0      9.82  \n",
      "1      0.13  \n",
      "2      7.80  \n",
      "3      0.09  \n",
      "4     11.25  \n",
      "5      8.41  \n",
      "6      0.05  \n",
      "7    -21.50  \n",
      "8      7.22  \n",
      "9      0.06  \n",
      "10   -26.00  \n",
      "11     4.35  \n",
      "12   -18.50  \n",
      "13     0.10  \n",
      "14     2.19  \n",
      "15     0.09  \n",
      "16   -16.00  \n",
      "17    41.60  \n",
      "18     1.46  \n",
      "19     0.21  \n",
      "20    22.50  \n"
     ]
    }
   ],
   "source": [
    "#Vemos el resultado\n",
    "print(df_merge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
