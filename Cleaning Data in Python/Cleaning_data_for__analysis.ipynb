{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando en un DataFrame tenemos variables de tipo string, pero estas variables deben ser categóricas, lo ideal es realizar la conversión a tipo categórica ya que con esto nos ahorramos espacio en memoria. Para esto disponemos del método **astype()** que nos permite realizar la conversión de un tipo de variable a otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_bill    float64\n",
      "tip           float64\n",
      "sex            object\n",
      "smoker         object\n",
      "day            object\n",
      "time           object\n",
      "size            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Cargamos el conjunto de datos\n",
    "tips = pd.read_csv('tips.csv')\n",
    "\n",
    "#Vemos el tipo de dato de cada una de las variables\n",
    "print(tips.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso las variables **smoker** y **sex** son de tipo **object** es la forma de indicar que se tratan de tipo **string**. Estas dos variables toman dos posibles valores, por lo que ambas, deberían ser de tipo categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_bill     float64\n",
      "tip            float64\n",
      "sex           category\n",
      "smoker        category\n",
      "day             object\n",
      "time            object\n",
      "size             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Convertimos a tipo categórica ambas variables\n",
    "tips.sex = tips.sex.astype('category')\n",
    "tips.smoker = tips.smoker.astype('category')\n",
    "\n",
    "#Vemos el tipo de dato de cada una de las variables\n",
    "print(tips.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with numeric data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si esperamos que una variable tome un valor numérico (**int** o **float**), pero sin embargo son del tipo **object**, podemos hacer uso de la función **pd.to_numeric()** para convertir una columna a tipo de dato numérico. Si al aplicar una función está nos retorna un error, podemos estar seguros de que existe algún valor de tipo no numérico en nuestra columna. Para resolver este problema podemos intentar analizar los datos y ver estos valores e intentar tomar una decisión simplemente hacer uso del argumneto **coerce** de la función **pd.to_numeric()**, si este argumento toma el valor de **True** lo que hace es transformar a tipo numérico aquellos valores que pueda y aquellos que no pueda los pondrá a valor **NaN**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String parsing with regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las expresiones regulares se trata de una herramienta muy potente que nos permite encontrar patrones en strings. Cuando estamos trabajando con datos, en muchas ocasiones es necesario escribir expresiones regulares que nos permitan machear determinados valores. Por ejemplo, en un campo que indique números de teléfono debemos de chequear para ver si todos los valores son válidos, los mismo podría pasar para una columna que contenga emails o que contenga DNIs.\n",
    "El módulo usado por parte de Python para trabajar con expresiones regulares se trata del módulo **re**. Puesto que el patrón a buscar normalmente se usará para múltiples filas, lo mejor es compilar la expresión regular, para ello contamos con **re.compile()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importamos el módulo re\n",
    "import re\n",
    "\n",
    "#Nos creamos una expresión regular que nos permite machear el patron xxx-xxx-xxx siendo x un número entero entre 0 y 9\n",
    "prog = re.compile('\\d{3}-\\d{3}-\\d{3}')\n",
    "\n",
    "#Vemos si este patrón es seguido por un string determinado \n",
    "result = prog.match('676-407-606')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos retorna un dato de tipo **Match**, para ver si el patrón es encontrado o no pasamos a tipo booleano con el constructor **bool**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(bool(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting numerical values from strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer valores numéricos de strings es una tarea muy común. Cuando deseamos encontrat varios valores numéricos en un string podemos hacer uso de la función **re.findall()**. A esta función le pasamos la expresión regular y el string y nos retorna los valores que son macheados según la expresión regular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15', '5']\n"
     ]
    }
   ],
   "source": [
    "#Introducimos nuestra expresión regular que nos permite extraer números de strings\n",
    "matches = re.findall('\\d+', 'Rocio tiene 15 años y Juan tiene 5')\n",
    "\n",
    "#Mostramos el resultado\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Escribir una expresión regular que nos detecte un número decima de dos digitos con dollar al inicio\n",
    "result = bool(re.match(pattern = '\\$\\d*\\.\\d{2}', string = '$123.45'))\n",
    "\n",
    "#Mostramos el resultado\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Escribir una expresión que nos permite detectar una letra mayúscula seguida de un valor arbitrario de números o letras\n",
    "result = bool(re.match(pattern = '[A-Z]\\w*', string = 'Australia12'))\n",
    "\n",
    "#Vemos el resultado \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions to clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos tips,dispone de la columna sex, esta columna toma dos posibles valores, **Female** y **Male**, el objetivo no es otro reescribir de forma que cuando aparezca **Female** tome el valor de 1 y cuando aparezca **Male** tome el valor de 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Nos creamos la función\n",
    "def recode_sex(sex_value):\n",
    "    '''Function that recode the column sex to values 1 if the sex is Female, 0 if the sex is Male otherwise NaN value'''\n",
    "    if sex_value == 'Female':\n",
    "        return 1\n",
    "    elif sex_value == 'Male':\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size  sex_recode\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2           1\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3           0\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3           0\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2           0\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4           1\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "tips = pd.read_csv('tips.csv')\n",
    "\n",
    "#Aplicamos la función\n",
    "tips['sex_recode'] = tips.sex.apply(recode_sex)\n",
    "\n",
    "#Mostramos el resultado \n",
    "print(tips.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones lambda se tratan de funciones que nos permite realizar operaciones en una sola línea, lo que nos permite que nuestro código sea más legible. A continuación vamos a proceder a cargar un nuevo conjunto de datos **tips2.csv** este conjunto de datos contiene la misma información que tips, pero con una columna adicional llamada **total_dollar** que contiene el contenido de total_bill pero con un dollar al inicio, el objetivo es eliminar este símbolo de dollar de dos formas distintas haciendo uso de funciones **lambda**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size totall_dollar\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2        $16.99\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3        $10.34\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3        $21.01\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2        $23.68\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4        $24.59\n"
     ]
    }
   ],
   "source": [
    "#Cargamos y mostramos los datos\n",
    "tips2 = pd.read_csv('tips2.csv')\n",
    "print(tips2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos el signo de dollar haciendo uso del método replace()\n",
    "tips2['total_dollar_replace'] = tips2.totall_dollar.apply(lambda x: x.replace('$', \"\"))\n",
    "\n",
    "#Eliminamos el signo de dollar a partir de expresión regular\n",
    "tips2['total_dollar_regex'] = tips2.totall_dollar.apply(lambda x: re.findall('\\d+\\.\\d+', x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size totall_dollar  \\\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2        $16.99   \n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3        $10.34   \n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3        $21.01   \n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2        $23.68   \n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4        $24.59   \n",
      "\n",
      "  total_dollar_replace total_dollar_regex  \n",
      "0                16.99              16.99  \n",
      "1                10.34              10.34  \n",
      "2                21.01              21.01  \n",
      "3                23.68              23.68  \n",
      "4                24.59              24.59  \n"
     ]
    }
   ],
   "source": [
    "#Mostramos el resultado\n",
    "print(tips2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping duplicate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos duplicados pueden causar una gran cantidad de problemas. Desde un punto de vista del rendimiento, pueden ocupar espacio en memoria de forma no necesaria. Para eliminar columnas repetidas, Python dispone de la función **drop_duplicates()**, esta función elimina filas repetidas en un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Equipo  Champions\n",
      "0  Real Madrid         13\n",
      "1  Real Madrid         13\n",
      "2       Milan           7\n",
      "3    Liverpool          5\n",
      "4    Barcelona          5\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "df = pd.read_csv('practica_duplicados.csv')\n",
    "\n",
    "#Vemos el conjunto de datos\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Equipo  Champions\n",
      "0  Real Madrid         13\n",
      "2       Milan           7\n",
      "3    Liverpool          5\n",
      "4    Barcelona          5\n"
     ]
    }
   ],
   "source": [
    "#Eliminamos duplicados\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#MOstramos el resultado \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando estamos tratando con conjuntos de datos, en la gran mayoría de las situaciones nos encontraremos con observaciones en las que tenemos valores perdidos. La forma de tratar estos valores perdidos es algo bastante amplio y existen una gran cantidad de técnicas para tratar este tema. Python a la hora de realizar la imputación de valores de perdidos dispone de la función **dropna()**, esta función lo que hace es eliminar todas las observaciones que contengan algún valor perdido, esta opción puede ser óptima en casos donde tengamos pocas observaciones con pocos valores perdidos, pero en situaciones donde tenemos una porcentaje considerable de observaciones con valores perdidos no es aconsejable. Por otro lado Python dispone de la función **fillna()** esta función permite completar los valores perdidos por el valor que le pasamos como argumento a esta función, esta opción pasa a ser óptima siempre y cuando estemos seguros de que los valores que estamos sustituyendo son adecuados. Estas formas son las más sencillas sin embargo existe una gran cantidad de literatura que nos permite tratar la imputación de una manera más sofisticada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 6 columns):\n",
      "Ozone      116 non-null float64\n",
      "Solar.R    146 non-null float64\n",
      "Wind       153 non-null float64\n",
      "Temp       153 non-null int64\n",
      "Month      153 non-null int64\n",
      "Day        153 non-null int64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 7.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "airquality = pd.read_csv('airquality.csv')\n",
    "\n",
    "#Vemos los columna que disponen de valores perdidos\n",
    "print(airquality.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver como las columnas Ozone y Solar.R disponen de valores perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153 entries, 0 to 152\n",
      "Data columns (total 6 columns):\n",
      "Ozone      153 non-null float64\n",
      "Solar.R    146 non-null float64\n",
      "Wind       153 non-null float64\n",
      "Temp       153 non-null int64\n",
      "Month      153 non-null int64\n",
      "Day        153 non-null int64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 7.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Calculamos la media de la variable Ozone\n",
    "mean_ozone = airquality.Ozone.mean()\n",
    "\n",
    "#Imputamos los valores perdidos por la media\n",
    "airquality['Ozone'] = airquality.Ozone.fillna(mean_ozone)\n",
    "\n",
    "#Vemos una vez más la info de airquality\n",
    "print(airquality.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing your data with asserts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método **assert** nos permite chequear para ver si ciertas situaciones en nuestro conjunto de datos se cumplen. En caso de que la condición aplicada en assert sea cierta este método no retornará nada, pero en caso de que dicha condición sea falsa retornará un error. El método **all()** nos retorna **True** o **False** en caso de que todos los valores cumplen esta condición. Para el caso de un dataframe un solo **all()** retornará una lista de True y False una para cada columna, si hacemos un **all()** anidado nos retornará un único True o False ya que se aplicará sobre todo el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-63ef7d2ceca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Vemos si nuestro conjunto de datos tiene algún valor no nulo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mebola\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Cargamos los datos\n",
    "ebola = pd.read_csv('ebola.csv')\n",
    "\n",
    "#Vemos si nuestro conjunto de datos tiene algún valor no nulo\n",
    "assert pd.notnull(ebola).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-787eb81cda7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Vemos si nuestro conjunto de datos tiene valores menores que 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mebola\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Vemos si nuestro conjunto de datos tiene valores menores que 0 \n",
    "assert (ebola >= 0).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puesto que en ambos casos aparecen un error, esto nos indica que disponemos de valores perdidos y que tenemos valores negativos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
