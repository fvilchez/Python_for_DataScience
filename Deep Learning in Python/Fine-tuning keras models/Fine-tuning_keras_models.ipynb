{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing optimization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a proceder a lanzar una red con un ratio de aprendizaje muy bajo, un rati de aprendizaje muy alto y un ratio de aprendizaje correcto. Cada vez que cambiamos la tasa de aprendizaje queremos que la optimización empiece desde cero, por lo que crearemos la función **get_new_model()** que crea un modelo no optimizado para que este sea optimizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s 277us/step - loss: 2.6613\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 45us/step - loss: 2.6522\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 41us/step - loss: 2.6432\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 43us/step - loss: 2.6342\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 40us/step - loss: 2.6254\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 47us/step - loss: 2.6166\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 45us/step - loss: 2.6080\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 45us/step - loss: 2.5994\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 44us/step - loss: 2.5910\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 43us/step - loss: 2.5827\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s 337us/step - loss: 1.9160\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 44us/step - loss: 0.6725\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 40us/step - loss: 0.6257\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 37us/step - loss: 0.6439\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 35us/step - loss: 0.6663\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 36us/step - loss: 0.6080\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 40us/step - loss: 0.5972\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 41us/step - loss: 0.6074\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 35us/step - loss: 0.5991\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 36us/step - loss: 0.5949\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s 325us/step - loss: 9.6615\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 42us/step - loss: 9.9314\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 48us/step - loss: 9.9314\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 41us/step - loss: 9.9314\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 39us/step - loss: 9.9314\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 42us/step - loss: 9.9314\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 54us/step - loss: 9.9314\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 47us/step - loss: 9.9314\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 41us/step - loss: 9.9314\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 41us/step - loss: 9.9314\n"
     ]
    }
   ],
   "source": [
    "#Cargamos las librerías necesarias\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def get_new_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation = \"relu\", input_shape = (input_shape,)))\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "    return model\n",
    "\n",
    "#Cargamos los datos\n",
    "df = pd.read_csv(\"titanic_all_numeric.csv\")\n",
    "\n",
    "#Convertimos la variable objetivo a tipo categórica\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "#Pasamos a tipo numpy matrix las variables que usaremos en el modelo \n",
    "np_predictors = df.iloc[:, 1:].values\n",
    "\n",
    "#Ahora obtenemos el número de predictores\n",
    "n_predictors = np_predictors.shape[1]\n",
    "\n",
    "#Nos creamos un vector de ratio de aprendizaje\n",
    "lr_to_test = [.000001, 0.01, 1]\n",
    "\n",
    "#Nos creamos un bucle para ejecutar un nuevo modelo con cada ratio de aprendizaje\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    #Construimos un nuevo modelo\n",
    "    model = get_new_model(n_predictors)\n",
    "    \n",
    "    #Nos creamos nuestro propio optimizador\n",
    "    my_optimizer = SGD(lr = lr)\n",
    "    \n",
    "    #Compilamos \n",
    "    model.compile(optimizer = my_optimizer, loss = \"categorical_crossentropy\")\n",
    "    \n",
    "    #Fijamos el modelo\n",
    "    model.fit(np_predictors, target, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating model accuracy on validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente debemos de validar la precisión de nuestro modelo con un conjunto de datos de validación. Para esto contamos en el momento de fijar el modelo con el argumento **validation_split** que nos permite indicar el porcentaje de los datos que queremos usar para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/10\n",
      "623/623 [==============================] - 0s 600us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n",
      "Epoch 2/10\n",
      "623/623 [==============================] - 0s 48us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n",
      "Epoch 3/10\n",
      "623/623 [==============================] - 0s 50us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n",
      "Epoch 4/10\n",
      "623/623 [==============================] - 0s 55us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n",
      "Epoch 5/10\n",
      "623/623 [==============================] - 0s 59us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n",
      "Epoch 6/10\n",
      "623/623 [==============================] - 0s 49us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n",
      "Epoch 7/10\n",
      "623/623 [==============================] - 0s 51us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n",
      "Epoch 8/10\n",
      "623/623 [==============================] - ETA: 0s - loss: 8.0590 - acc: 0.500 - 0s 48us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n",
      "Epoch 9/10\n",
      "623/623 [==============================] - 0s 66us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n",
      "Epoch 10/10\n",
      "623/623 [==============================] - 0s 64us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a43836cc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Complilamos el modelo, con el argumento \"metrics\" = \"accuracy\" con el fin de ver el porcentaje de acierto de nuestro\n",
    "#clasificador.\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "#Fijamos el modelo dejando un 30% del conjunto de datos para validación\n",
    "model.fit(np_predictors, target, epochs = 10, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping: Optimizing the optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya conocemos como optimizar nuestro modelo, podemos parar esta optimización en el momento que detecte que ya no va a mejorar. Esto nos permite seleccionar un número de epochs bastante elevado, ya que en el momento que se detecte que no existe una mejora el modelo parará."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 0s 688us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 56us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 62us/step - loss: 9.7536 - acc: 0.3949 - val_loss: 10.3444 - val_acc: 0.3582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a42dc38d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargamos la función que nos permite realizar la acción de parar el modelo cuando deje de mejorar\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#Compilamos el modelo\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "#Indicamos que pare el modelo en caso de que pasen 2 epochs y no mejore\n",
    "early_stopping_monitor = EarlyStopping(patience = 2)\n",
    "\n",
    "#Procedemos a fijar el modelo\n",
    "model.fit(np_predictors, target, epochs = 30, validation_split = 0.3, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 22.0, 1, ..., 0, 0, 1],\n",
       "       [1, 38.0, 1, ..., 1, 0, 0],\n",
       "       [3, 26.0, 0, ..., 0, 0, 1],\n",
       "       ..., \n",
       "       [3, 29.69911764705882, 1, ..., 0, 0, 1],\n",
       "       [1, 26.0, 0, ..., 1, 0, 0],\n",
       "       [3, 32.0, 0, ..., 0, 1, 0]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with wider networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a comparar el rendimiento para dos modelos distintos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a4079c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Indicamos la condición de parada del modelo\n",
    "early_stopping_monitor = EarlyStopping(patience = 2)\n",
    "\n",
    "#Nos creamos el primer modelo\n",
    "model_1 = Sequential()\n",
    "\n",
    "#Nos creamos la primera capa oculta\n",
    "model_1.add(Dense(10, activation = \"relu\", input_shape = (n_predictors,)))\n",
    "\n",
    "#Nos creamos la segunda capa oculta\n",
    "model_1.add(Dense(10, activation = \"relu\"))\n",
    "\n",
    "#Nos creamos la capa de salida\n",
    "model_1.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "#Nos creamos el segundo modelo\n",
    "model_2 = Sequential()\n",
    "\n",
    "#Nos creamos la primera capa oculta \n",
    "model_2.add(Dense(100, activation = \"relu\", input_shape = (n_predictors,)))\n",
    "\n",
    "#Nos creamos la segunda capa oculta\n",
    "model_2.add(Dense(100, activation = \"relu\"))\n",
    "\n",
    "#Nos creamos la capa de salida\n",
    "model_2.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "#Compilamos los dos modelos\n",
    "model_1.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model_2.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "#Ahora procedemos a fijar o entrenar los modelos\n",
    "trainnig_model_1 = model_1.fit(np_predictors, target, validation_split = 0.2, epochs = 15, \n",
    "                               callbacks = [early_stopping_monitor], verbose = False)\n",
    "\n",
    "trainnig_model_2 = model_2.fit(np_predictors, target, validation_split = 0.2, epochs = 15,\n",
    "                               callbacks = [early_stopping_monitor], verbose = False)\n",
    "\n",
    "#Visualizamos los resultados de ambos modelos\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(trainnig_model_1.history[\"val_loss\"], \"r\", trainnig_model_2.history[\"val_loss\"], \"b\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
