{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding the forward propagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicios vamos a proceder a programar nuestra primer red neuronal de tipo **forward**. Cada dato es un cliente. La primera neurona de la red de entrada es el número de cuentas que dicho cliente tiene abiertas, la segunda neurona es el número de hijos que tiene dicho cliente. El modelo debe ser de capaz de predecir el número de transacciones que realizará dicho cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-39"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importamos librerías\n",
    "import numpy as np \n",
    "\n",
    "#Nos creamos los datos de entrada\n",
    "input_data = np.array([3, 5])\n",
    "\n",
    "#Nos creamos los datos asociados a cada una de las capas\n",
    "weights = {\"node_0\": np.array([2,4]), \"node_1\": np.array([4, -5]), \"output\": np.array([2, 7])}\n",
    "\n",
    "#Calculamos el valor que nos retorna el nodo 0\n",
    "node_0_value = (weights[\"node_0\"] * input_data).sum()\n",
    "\n",
    "#Calculamos el valor que nos retorna el nodo 1\n",
    "node_1_value = (weights[\"node_1\"] * input_data).sum()\n",
    "\n",
    "#Unimos la info\n",
    "hidden_layer_output = np.array([node_0_value, node_1_value])\n",
    "\n",
    "#Calculamos le valor predicho \n",
    "predicted_value = (weights[\"output\"] * hidden_layer_output).sum()\n",
    "\n",
    "#Mostramos el valor predicho\n",
    "predicted_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Rectified Linear Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de activación se trata de una función matemática que se aplica a cada nodo, de forma que transforma el valor de entrada de dicho nodo en una salida. Se ha demostrado que la función de activación de rectificación lineal (ReLU) conduce a redes de alto rendimiento. Esta función toma como entrada un simple número y retorna 0 si dicho valor es negativo y el propio número en caso contrario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "#Nos definimos la función de activación de ReLU\n",
    "def relu(input):\n",
    "    output = max(0, input)\n",
    "    return(output)\n",
    "\n",
    "#Calculamos el valor que retorna el nodo 0 tras aplicarle la función de relu\n",
    "node_0_value_input = (weights[\"node_0\"] * input_data).sum()\n",
    "node_0_value_output = relu(node_0_value_input)\n",
    "\n",
    "#Calculamos el valor que retorna el nodo 1 tras aplicarle la función de relu\n",
    "node_1_value_input = (weights[\"node_1\"] * input_data).sum()\n",
    "node_1_value_output = relu(node_1_value_input)\n",
    "\n",
    "#Unimos la info\n",
    "hidden_layer_output = np.array([node_0_value_output, node_1_value_output])\n",
    "\n",
    "#Ahora calculamos el valor predicho\n",
    "model_output = (weights[\"output\"] * hidden_layer_output).sum()\n",
    "\n",
    "#Mostramos el resultado\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the network to many observations/rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a proceder a crear una función denominada **predict_with_network** la cual genera predicciones para múltiples observaciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52, 63, 0, 148]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_with_network(input_data_row, weights):\n",
    "    \n",
    "    #Calculamos los resultados para el nodo 0\n",
    "    node_0_input = (weights[\"node_0\"] * input_data_row).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "    \n",
    "    #Calculamos los resultados para el nodo 1\n",
    "    node_1_input = (weights[\"node_1\"] * input_data_row).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "    \n",
    "    #Unimos los resultados\n",
    "    hidden_layer_output = np.array([node_0_output, node_1_output])\n",
    "    \n",
    "    #Retornamos el valor predicho\n",
    "    return((weights[\"output\"] * hidden_layer_output).sum())\n",
    "\n",
    "\n",
    "#Nos creamos los datos de entrada\n",
    "input_data = [np.array([3,5]), np.array([1, -1]), np.array([0, 0]), np.array([8, 4])]\n",
    "\n",
    "#Aplicamos la función para ver que resultados obtenemos\n",
    "results = [predict_with_network(value, weights) for value in input_data]\n",
    "\n",
    "#Mostramos los resultados\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a proceder a realizar el código que simularía a red neuronal con dos capas ocultas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182, 162, 0, 392]\n"
     ]
    }
   ],
   "source": [
    "#Nos creamos la función que nos permite simular una red neuronal con dos capas ocultas\n",
    "def multilayer_network(input_data_row, weights):\n",
    "    #Calculamos la salida del nodo 0 de la primera capa oculta\n",
    "    node_0_0_input = (weights[\"node_0_0\"] * input_data_row).sum()\n",
    "    node_0_0_output = relu(node_0_0_input)\n",
    "    \n",
    "    #Calculamos la salida del nodo 1 de la primera capa oculta\n",
    "    node_0_1_input = (weights[\"node_0_1\"] * input_data_row).sum()\n",
    "    node_0_1_output = relu(node_0_1_input)\n",
    "    \n",
    "    #Unimos los resultados\n",
    "    firs_hidden_layer_output = np.array([node_0_0_output, node_0_1_output])\n",
    "    \n",
    "    #Calculamos la salida del nodo 0 de la segunda capa oculta\n",
    "    node_1_0_input = (weights[\"node_1_0\"] * firs_hidden_layer_output).sum()\n",
    "    node_1_0_output = relu(node_1_0_input)\n",
    "    \n",
    "    #Calculamos la salida del nodo 1 de la segunda capa oculta\n",
    "    node_1_1_input = (weights[\"node_1_1\"] * firs_hidden_layer_output).sum()\n",
    "    node_1_1_output = relu(node_1_1_input)\n",
    "    \n",
    "    #Unimos los resultados\n",
    "    second_hidden_layer_output = np.array([node_1_0_output, node_1_1_output])\n",
    "    \n",
    "    #Obtenemos y hacemos un return de las predicciones\n",
    "    return (weights[\"output\"] * second_hidden_layer_output).sum()\n",
    "\n",
    "#Nos creamos los pesos de la red\n",
    "weights = {\"node_0_0\": np.array([2, 4]), \"node_0_1\": np.array([4, -5]), \"node_1_0\": np.array([-1, 2]),\n",
    "          \"node_1_1\": np.array([1, 2]), \"output\": np.array([2, 7])}\n",
    "\n",
    "\n",
    "#Hacemos llamada a la función\n",
    "predic = [multilayer_network(value, weights) for value in input_data]\n",
    "print(predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
