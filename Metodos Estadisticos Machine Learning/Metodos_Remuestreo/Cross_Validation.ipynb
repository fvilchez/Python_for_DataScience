{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation es un método estadístico usado para estimar las habilidades de los modelos de aprendizaje automático. Es comunmente usado en el aprendizaje automático aplicado para comparar y seleccionar un modelo para un problema predictivo determinado. Se trata de un método fácil de comprender, implementar y los resultados generalmente tienen un sesgo menor que otros métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation es un procedimiento de remuestreo usado para evaluar modelos de aprendizaje automático en un conjunto de datos limitado. El procedimiento tiene un único parámetro llamado **k** que se refiere al número de grupos en los que se dividirá una muestra dada. Cross-Validation es principalmente usado en el aprendizaje automático para estimar la capacidad de un modelo con datos no vistos. El procedimiento que sigue es el siguiente.\n",
    "\n",
    "* Mezclamos los datos de forma aleatoria.\n",
    "\n",
    "* Separamos el conjunto de datos en k grupos\n",
    "\n",
    "* Para cada grupo:\n",
    "\n",
    " * Tomamos un grupo completo como conjunto de test\n",
    " \n",
    " * Tomamos el resto de grupos como conjunto de entrenamiento\n",
    " \n",
    " * Fijamos el modelo con el conjunto de entrenamiento y evaluamos con el test\n",
    " \n",
    " * Convervamos el resultado de la evalución y descartamos el modelo\n",
    " \n",
    "* Resumimos la capacidad del modelo a partir de los scores obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante, cada observación en la muestra de datos es asignada a un grupo individual permaneciendo en este grupo durante el procedimiento. Esto significa que cada muestra es usada 1 vez en el conjunto de test y k-1 veces en el conjunto de entrenamiento. Este enfoque implica dividir aleatoriamente el conjunto de observaciones en k grupos o folds, todos ellos de un tamaño apróximadamente igual.\n",
    "\n",
    "El resultado del procedimiento k-fold cross-validation es a menudo resumido mediante la media. Es una buena práctica acompañar a esta métrica otras como la desviación estándar o el error estándar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuración de k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor de **k** debe ser elegido cuidadosamente para la muestra de datos. Un valor de **k** mal elegido puede dar lugar a resultados que no representen de forma correcta las capacidades de nuestro modelo, obteniendo por ejemplo resultados con una elevada varianza o un sesgo elevado. Existen numerosas técnicas para seleccionar el valor de **k**, entre las que destacan:\n",
    "\n",
    "* **Representativa:** el valor de k debe ser elegido de forma que cada conjunto de entrenamiento y de test en cada fold sea lo suficientemente grande como para que sea representativo.\n",
    "\n",
    "* **k=10:** se trata de un valor que a partir de la experimentación se ha encontrado que generalmente da resultados con un sesgo bajo y una varianza modesta.\n",
    "\n",
    "* **k=n:** el valor de k es fijado al número de observaciones de nuestro conjunto de datos. De forma que se crea un conjunto de entrenamiento con todas las muestras menos una la cual es usada como conjunto de test. Esta técnica también es conocida como leave-one-out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería scikit-learn dispone de la clase **KFold()** que puede ser usada para hacer uso de este técnica. Esta toma como argumentos el números de particiones (n_splits), un parámetro booleano que nos permite indicar si queremos barajar o no la muestra (shuffle) y la semilla pseudoaleatoria (random_state).\n",
    "\n",
    "La función **split()** puede ser usada cuando le pasamos directamente a nuestro KFold la muestra de datos, si llamamos a este función de forma repetida obtendremos los grupos de train y test creados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.1 0.2 0.3 0.5], test: [0.4 0.6]\n",
      "train: [0.2 0.4 0.5 0.6], test: [0.1 0.3]\n",
      "train: [0.1 0.3 0.4 0.6], test: [0.2 0.5]\n"
     ]
    }
   ],
   "source": [
    "#Generamos una muestra\n",
    "data = np.array([0.1,0.2,0.3,0.4,0.5,0.6])\n",
    "\n",
    "#Generamos el KFold\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=7)\n",
    "\n",
    "#Mostramos el resultado\n",
    "for train,test in kfold.split(data):\n",
    "    print('train: %s, test: %s' % (data[train], data[test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variaciones de Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen una serie de variaciones respecto al procedimiento k-fold.\n",
    "\n",
    "* **Train/Test Split:** se trata de un k-fold con k=1\n",
    "\n",
    "* **Stratified:** se dividen los datos en folds pero estos son realizados a partir de un criterio para asegurarnos que cada fold tiene la misma proporción de observaciones para un valor categórico determinado.\n",
    "\n",
    "* **Repeated:** el procedimiento de k-fold es repetido n-veces, donde la muestra de datos es barajada antes de cada repetición."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
