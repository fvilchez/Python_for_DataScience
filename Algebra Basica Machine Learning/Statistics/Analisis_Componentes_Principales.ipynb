{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Que es el Análisis de Componentes Principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis de componentes principales se trata de un método para reducir la dimensionalidad de los datos. Se trata de un método que usa operaciones matriciales y estadísticos para calcular una proyección de los datos originales en un número menor de dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede pensar como un método que proyecta nuestras m columnas (características) en un sub-espacio con m o menos columnas, mientras retiene la esencia de los datos originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = \\begin{pmatrix}a_{1,1} & a_{1,2}\\\\\\ a_{2,1} & a_{2,2}\\\\\\ a_{3,1} & a_{3,2}\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso consiste es calcular los valores medios para cada columna\n",
    "\n",
    "$$ M = mean(A)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso, es centrar los valores de cada columna, para ellos le restamos a cada valor de cada columna la media de su columna correspondiente.\n",
    "\n",
    "$$C = A - M$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es calcular la matriz de covarianza para nuestra matriz centrada C.\n",
    "\n",
    "$$ V = cov(C) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente calculamos la descomposición en vectores y valores propios de nuestra matriz de covarianza.\n",
    "\n",
    "$$value, vectors = eig(V)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los vectores propios representan las direcciones o componentes para el subespacio reducido B, mientras que los valores propios representan las magnitudes de las direcciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los vectores propios puede ser ordenados de forma descendente a partir del valor propio que les acompaña con el objetivo de proporcionar un ranking de las componentes o ejes del nuevo subespacio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todos los valores propios tiene un valor similar, entonces podemos concluir que la representación actual está razonablemente comprimida y la proyección a un nuevo espacio no aportará en exceso.\n",
    "\n",
    "Aquellos valores propios cercanos a cero nos indican aquellas componentes que podemos descartar para el nuevo subespacio B.\n",
    "\n",
    "Idealmente queremos seleccionar k vectores propios, llamados componentes principales, que tienen k valores propios elevados.\n",
    "\n",
    "$$B = select(values, vectors)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez seleccionados estos vectores propios podemos proceder a proyectos nuestros datos originales en el nuevo subespacio, para esto:\n",
    "\n",
    "$$P = B^{T}A$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde A son los datos originales que deseamos proyectar, B es la matriz con los vectores propios seleccionados, finalmente P es la proyección de A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando el análisis de componentes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de realizar esta cálculo mediante Python, tenemos dos opciones, si optamos por hacer uso de Numpy no disponemos de ninguna función que nos permita realizar este cálculo de forma directa, sin embargo si optamos por hacer uso de ScikitLearn, este módulo si que dispone de la clase PCA que nos permite calcular de forma directa el análisis de componentes principales. A continuación veamos como se realizaría este cálculo haciendo uso de Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8. 0.]\n",
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "#Generamos nuestro conjunto de datos A\n",
    "A = np.array([[1,2], [3,4], [5,6]])\n",
    "\n",
    "#Calculamos la media de cada una de las columnas \n",
    "A_mean_col = np.mean(A.T, axis = 1)\n",
    "\n",
    "#Centramos restando la media\n",
    "C = A - A_mean_col\n",
    "\n",
    "#Calculamos la matriz de covarianza\n",
    "V = np.cov(C.T)\n",
    "\n",
    "#Descomponemos en vectores y valores propios\n",
    "values, vectors = eig(V)\n",
    "print(values)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.82842712  0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.82842712  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Proyectamos los datos\n",
    "P = vectors.T.dot(C.T)\n",
    "print(P.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando el análisis de componentes principales con Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular el análisis de componentes principales haciendo uso de la clase **PCA()** de la librería scikit-learn. El principal beneficio es que una vez es calculada la proyección, esta puede ser aplicada a los datos una y otra vez con bastante facilidad. Podemos especificar el número de componentes principales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70710678  0.70710678]\n",
      " [ 0.70710678 -0.70710678]]\n",
      "[8.00000000e+00 2.25080839e-33]\n"
     ]
    }
   ],
   "source": [
    "#Generamos nuestro array\n",
    "A = np.array([[1,2], [3,4], [5,6]])\n",
    "\n",
    "#Creamos el modelo \n",
    "pca = PCA(2)\n",
    "\n",
    "#Fijamos el modelo \n",
    "pca.fit(A)\n",
    "\n",
    "#Vemos las componentes y la varianza explicada por cada componente\n",
    "print(pca.components_)\n",
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.82842712e+00  2.22044605e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 2.82842712e+00 -2.22044605e-16]]\n"
     ]
    }
   ],
   "source": [
    "#Hacemos el transform\n",
    "B = pca.transform(A)\n",
    "print(B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
